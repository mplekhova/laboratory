{
    "title": "TCP/IP Outdated for Big Data Transport, Quiet Company Says",
    "author": "Doug Black",
    "date": "2017-04-26 00:00:00",
    "text": "In network technology circles there\u2019s a joke about \u201cnever underestimating the bandwidth capacity of a station wagon full of tapes driving down the highway.\u201d In the same vein, at re:Invent last fall, Amazon Web Services announced with fanfare \u2013 and some humor \u2013 a service for transferring up to 100PB of data to AWS in a 45-foot long shipping container pulled by an 18-wheeler semitruck.As data volumes grow, the basic internet communication protocol, TCP/IP \u2013 now approaching 45 years old \u2013\u00a0 is frequently overwhelmed when called upon for large-scale data transfers. There are work-arounds and data transfer boosters, but TCP/IP is something of an anachronism, a choke point in many advanced scale computing infrastructures.Or, as Eric Hanselman, chief analyst at 451 Research, told EnterpriseTech: \u201cAny time you have AWS rolling out a tractor trailer full of storage, you know we\u2019ve got a data transit problem.\u201dSeth Noble, founder of little known Data Expedition, formed in 2000 and with a customer roster of 200 companies (Associated Press, Disney, Motorola, Lockheed Martin), has quietly toiled on the data transfer problem for nearly 25 years. This week the company announced CloudDat, data transport software based on the company\u2019s Multipurpose Transaction Protocol (MTP/IP), which Data Expedition said moves data at up to 900mb/second per instance over commodity internet lines (compared with 100-150mb/second using TCP/IP). The company claims MTP/IP delivers an average 7X performance advantage over TCP/IP, though that number varies depending on customer deployment.Data Expedition said CloudDat is now natively integrated into Oracle\u2019s DIVA Cloud Service for managing digital media assets. In addition, CloudDat supports data transfer into and out of AWS, Microsoft Azure and Google Cloud Platform, along with on-prem cloud infrastructures.\u201cWhat they\u2019ve done is put together an environment that\u2019s attractive for users with very large volumes of data,\u201d Hanselman said, \u201cThose are folks for whom a performance improvement in transfer times makes a really big difference because of the size of the volumes of data they\u2019re moving.\u201dAlong with its MTP/IP protocol, Expedition\u2019s product line have integrated instrumentation that accumulate intelligence about transmit paths and optimizes network performance.\u201cThe protocol is useful in that it\u2019s smarter about the way in which it manages the exchange of data,\u201d Hanselman said. \u201cBut they\u2019ve also put in place the necessary instrumentation within the whole protocol stack that dynamically understands the nature of the network in use and responds to it effectively. They\u2019re actually looking at that transmit path as data is being transferred and adapting the best techniques for whatever prevailing conditions there are and to adapt them over time. Networks are very dynamic things.\"They\u2019ve spent the time and invested the effort to be able to build something that\u2019s flexible enough and capable enough to solve what is a significant need.\"One customer is Amagi, a cloud-based managed broadcast services and targeted advertising company based in Bangalore with deployments in 40+ countries managing 80+ feeds. With 12TBs of download and 2TBs of upload across all its customers each month, the company four years ago looked for a new way to move massive amounts of content and settled on ExpeDat, Data Expedition\u2019s flagship product.\u201cWhen we first used ExpeDat, it gave us 10X or more transfer speed,\u201d said Srividhya Srinivasan, Amagi co-founder. \u201cOur first reaction was, \u2018Are we really seeing the right thing?\u2019\u2026 Perceptually and visually, our customers do not know we are using ExpeDat. But they do know, if they are working with Amagi, their data transport is going to be quite fast and we will take care of transferring their content anywhere around the globe\u2026 We have never had a case where we had any limitation or issue with scaling or anything else.\u201dThe key to the software, Noble told EnterpriseTech, is its ability to utilize the full potential of data paths, to move data faster by making the network itself more efficient. And because it\u2019s a pure software solution, CloudDat can be deployed alongside traditional applications without changing or disrupting existing networks.\u201cThe basic idea is that when you\u2019re trying to transfer data over the internet or any packet switched networks, it\u2019s a black box,\u201d Noble said. \u201cYou throw a packet out there and you don\u2019t know what happens until something comes back and talks to you. TCP/IP looked at the problem through the lens of 1974 networks and usage\u2026. We\u2019ve tried to focus on the way data moves around in modern networks.\u201dNoble does not provide extensive detail on the network optimization technology, he discusses it primarily in conceptual terms and highlights the promised benefits. This may be to keep the company\u2019s secret sauce a secret \u2013 or because he realizes that no one other than a network specialist could understand how the technology works.\u201cIt doesn\u2019t matter if you\u2019re transferring data over a kilobit per second network or a multi-GB per second network, whether it\u2019s around the corner or across the world, it automatically figures out the right thing to do and transfers the data at the correct speed \u2013 not overflowing the network and not underutilizing the network,\u201d said Noble. \u201cIt\u2019s really important it\u2019s able to do this without human intervention because of course most people don\u2019t know and shouldn\u2019t know the details of how their network connection works.\u201dHanselman said Data Expedition is unique for the general-purpose nature of its technology, which can be implemented in a relatively straightforward way. He cited other high-volume data transport protocols, such as XTP, that he said can be difficult to integrate.\u201cThe thing that these guys have done is really put the time and effort in,\u201d he said. \u201cThe question for a lot of this is: how much do the application users, who by default normally use TCP or UDP and overlay their own capabilities on it, how much work do they want to do, how many dependencies do you then have at this intermediate layer with the new protocol, how much do you have to mess around with your customer\u2019s environment to actually adapt them to it\u2026 For most typical applications it\u2019s not worth the time and trouble to look into better ways of managing (data transit).\"Hanselman cited the typical example of transferring a complete machine image - \u201cvirtual instances that are big, multi-gigabyte images of virtual machines. Now it\u2019s a reasonable thing to be able to push those up into the cloud environment, CloudDat is a gateway function that allows them to make the best optimization of the link between an on-premises data center and whatever the cloud environment is. If you don\u2019t have a dedicated cloud connextion your ability to transfer data to the cloud is going to be catastrophic. When you move a full vitural machine up into the cloud, that can be significantly impacted by networking conditions.\"Hanselman said there also are cloud storage gateway companies working to enhance data transport, but these efforts are usually integrated with their own products. \u201cData Expedition has a much more general purpose functionality, as opposed to dedicated capabilities.\u201dAnother Data Expedition customer is Children\u2019s Hospital of Philadelphia, which is generating high volumes of data in the course of its ongoing genomics research \u2013 databases that are processed, regenerated and transferred from one facility to another.\u201cThey have terabytes of data at time that need to be distributed to other research institutions,\u201d Noble said. \u201cThe end user may not even know we\u2019re there under the hood, but it\u2019s helping moving all this data between all those HPC centers.\u201d",
    "pic_urls": [
        "https://2pggys3b7fd63bfvol1w51zt-wpengine.netdna-ssl.com/wp-content/uploads/2017/03/shutterstock_world_data-370x228.jpg",
        "https://2pggys3b7fd63bfvol1w51zt-wpengine.netdna-ssl.com/wp-content/uploads/2017/04/Data-Expedition-logo-300x58.png"
    ]
}