{
    "title": "Chip Startup Accelerates AI with MRAM",
    "text": "The AI chip market continues to heat up with the recent release of a series of AI accelerators with embedded memory that target the booming edge computing sector.Gyrfalcon Technology Inc.\u00a0(GTI) said its \u201cproduction-ready\u201d ASIC,\u00a0dubbed the Lightspeeur 2802M, incorporates low-power embedded MRAM as the Silicon Valley startup zeroes in on what it calls \u201cEdge AI.\u201d Taiwanese chip foundry TSMC (NYSE: TSM) began manufacturing the 22-nanometer design last June, incorporating its embedded MRAM process technology.The combination leverages on-chip memory as an AI processor, reducing data movement among edge devices while accelerating the processing of AI models.The startup based in Milpitas, Calif., emphasizes the ratio between accelerated AI performance and the low-power, non-volatility attributes of its proprietary \u201cMRAM engine.\u201d The 40 MB embedded memory is designed to support either large AI models or multiple models on a single ASIC. Those models could include image classification, facial recognition or voice commands.Launched in December,\u00a0Lightspeeur 2802M is the first in a series of planned embedded MRAM chips the startup plans to extend to what it refers to as \u201csuper AI accelerator chips.\u201d The architecture pairs GTI\u2019s MRAM engine with a \u201cmatrix processing engine\u201d based on convolutional neural networks as well as its \u201cAI Processing in Memory\u201d framework.\u201cThis optimizes the speed of processing, achieving high [theoretical operations per second] performance, while also saving tremendous amounts of power by avoiding management of data in discrete memory components,\u201d the company said.The Lightspeeur AI accelerator technology also has been incorporated into a USB stick. The startup touts the Laceli AI compute stick as delivering better performance with 90x the power efficiency compared to Intel\u2019s (NASDAQ: INTC) Movidius Neural Compute Stick\u00a0unveiled in July 2017.The GTI accelerator chips support AI models based on Caffe, TensorFlow and other tools to develop neural networks and other machine learning frameworks, the company said.Along with AI accelerator competitors Intel and graphics chip leader Nvidia (NASDAQ: NVDA), the AI chip startup also is aiming variations of its Lightspeeur design at cloud servers.GTI claims its 16-chip server (based on the 28nm Lightspeeur 2803S) can outhustle Nvidia\u2019s Tesla processor both in terms of performance and power efficiency, delivering 271 TOPS at 28 watts (as reported by Synced).As proliferation of edge devices boosts requirements for in-memory processing, approaches such as GTI\u2019s also are boosting the prospects for MRAM, which stands for magneto-resistive random-access memory. As AI applications proliferate, the power, density and data-preserving attributes of MRAM may help it surpass dominant SRAM technology, observers note.George Leopold has written about science and technology for more than 30 years, focusing on electronics and aerospace technology. He previously served as executive editor of Electronic Engineering Times. Leopold is the author of \"Calculated Risk: The Supersonic Life and Times of Gus Grissom\" (Purdue University Press, 2016).",
    "author": [
        "George Leopold",
        "https://www.enterpriseai.news/author/george/"
    ],
    "date": "2019-01-31 00:00:00",
    "cats": [
        "AI/ML/DL",
        "Cloud",
        "Silicon",
        "Slider: Cloud",
        "Slider: Silicon",
        "Slider: Storage",
        "Slider: Systems",
        "Storage",
        "Systems"
    ],
    "cat_urls": [
        "https://www.enterpriseai.news/category/ai-ml-dl/",
        "https://www.enterpriseai.news/category/cloud/",
        "https://www.enterpriseai.news/category/silicon/",
        "https://www.enterpriseai.news/category/slider-cloud/",
        "https://www.enterpriseai.news/category/slider-silicon/",
        "https://www.enterpriseai.news/category/slider-storage/",
        "https://www.enterpriseai.news/category/slider-systems/",
        "https://www.enterpriseai.news/category/storage/",
        "https://www.enterpriseai.news/category/systems/"
    ],
    "tags": [
        "AI accelerator",
        "edge computing",
        "GTI",
        "Gyrfalcon Technology Inc.",
        "in-memory",
        "Lightspeeur",
        "MRAM",
        "on-chip memory"
    ],
    "tag_urls": [
        "https://www.enterpriseai.news/tag/ai-accelerator/",
        "https://www.enterpriseai.news/tag/edge-computing/",
        "https://www.enterpriseai.news/tag/gti/",
        "https://www.enterpriseai.news/tag/gyrfalcon-technology-inc/",
        "https://www.enterpriseai.news/tag/in-memory/",
        "https://www.enterpriseai.news/tag/lightspeeur/",
        "https://www.enterpriseai.news/tag/mram/",
        "https://www.enterpriseai.news/tag/on-chip-memory/"
    ],
    "pic_urls": [
        "https://2pggys3b7fd63bfvol1w51zt-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/edge-computing-shutterstock_1248277756--370x290.jpg",
        "https://2pggys3b7fd63bfvol1w51zt-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/GTI-Laceli-AI-compute-stick-300x200.jpg",
        "https://secure.gravatar.com/avatar/4b7d4d569774f21b5db4f21ac8c19c8d?s=80&r=g"
    ]
}