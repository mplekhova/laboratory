{
    "title": "NCSA Industry Conference Recap \u2013 Part 2",
    "author": "no author",
    "date": "2018-10-31 00:00:00",
    "text": "Industry Program Director Brendan McGinty welcomed guests to the annual National Center for Supercomputing Applications (NCSA) Industry Conference, Oct. 9-11 in Urbana, Illinois. One hundred eighty from 40 organizations registered for the invitation-only, two-day event.Day two opened with a keynote address by NCSA Director William Gropp, who explained how advanced computation has changed over the years, and where it\u2019s heading. He acknowledged that specialization has always driven how computers were designed, but it was largely ignored.\u201cMany were preoccupied with Moore\u2019s Law, which was always more of an imperative than a law,\u201d he said. He noted that today\u2019s Top500 list illustrates how specialization rules; the six most powerful systems on that list employ specialized processors which drive architecture, software and algorithms.NCSA supports democratized instrumentation and data initiatives to serve federated, and inter-federated research communities, according to Gropp. Through these associations, their portfolio has expanded, \u201cin new and exciting ways.\u201d For example, NCSA will serve as the global central hub for the Large Synoptic Survey Telescope (LSST), and will be responsible for processing, archiving and serving 15 terabytes of raw image data collected each night of the 10-year survey. \u201cLSST is expected to spawn a burgeoning telescope industry that will naturally look to NCSA to shape its future,\u201d he said. NCSA supports the Midwest Big Data Hub; NSF\u2019s first investment in data-sharing, as well as its third-generation compute-sharing project, the Extreme Science and Engineering Discovery Environment (XSEDE), led by Executive Director John Towns (UIUC Deputy CIO for Research IT).With quantum capability expected within five years, NCSA is always experimenting with new platforms and can advise partners when the use of accelerators, like GPUs or FPGAs, are recommended, for example. \u201cCloud-enabled resources have changed the high-performance computing (HPC) landscape,\u201d said Gropp.He emphasized the importance of conducting a feasibility assessment when deciding whether to host cloud systems. \u201cUnless you have a lot of work that\u2019s perfect for a dedicated cloud resource and can keep them busy, it makes sense to find a provider,\u201d he said.Following Gropp\u2019s presentation on Thursday, Christopher Alix, President of Prairie City Computing, led a session titled, \u201cEmerging Technologies in Artificial Intelligence (AI).\u201dUIUC Assistant Professor Chenhui Shao (Dept. of Mechanical Science and Engineering) described how improvements in communications, connectedness, computing, sensors, and AI have revolutionized manufacturing. \u201cSmart manufacturing is addressing the challenges of data fidelity, real-time learning and dynamic decision-making across multiple levels,\u201d Shao said, and added, \u201cWhile supercomputing is essential for big data analytics, smaller facilities do not have access to sufficient computing capability; this is another way that NCSA can help.\u201dNCSA Eliu Huerta is a UIUC Computational Science and Engineering Fellow and leads the NCSA Gravity Group. His presentation was titled, \u201cFrontiers at the Interface of Deep Learning (DL) and HPC.\u201d Since earning a PhD in Theoretical Astrophysics from the University of Cambridge, Huerta has gained experience with large-scale computing, deep and machine learning, theory, and modeling.Huerta presented a scientific visualization of the collision of two neutron stars that was first observed in gravitational waves by the Laser Interferometer Gravitational-Wave Observatory (LIGO) and Virgo detectors on August 17, 2017. \u201cThe DL algorithms NCSA has pioneered enable the observation of these spectacular events, both in gravitational waves and light, faster than real time. As NCSA continues to drive innovation at the interface of DL and HPC, we are laying the foundation to enable discovery at scale and in real-time when LSST and gravitational wave detectors perform simultaneous observations of these multi-messenger events,\u201d he said.Technical Assistant Director and Research Professor of Mechanical Engineering Seid Koric is Blue Waters\u2019 most prolific researcher. He has published more than 60 research papers, and 40 pertained to research conducted on Blue Waters with industrial and academic collaborators from around the world. Among the many awards he has received, are several HPCwire Readers\u2019 and Editors\u2019 Choice Awards, including Best Use of an HPC Application in Manufacturing.Koric chaired the session titled, \u201cIndustry Application Domain Updates.\u201d He explained that NCSA domain specialists work at the industry partner\u2019s pace, and under strict nondisclosure agreements. \u201cWe do what we can to ensure the work is delivered on time, and under budget,\u201d he said. NCSA offers specialization in visualization; modeling and simulation; bioinformatics and genomics; data analytics and AI; cyberinfrastructure and cybersecurity; code profiling and optimization; and more. \u201cWith more than 200 FTEs, there are always a broad range of specialists available,\u201d said Koric. And it\u2019s a diverse community of practice; he mentioned that among 40 active collaborations, eight native languages are represented.Technical Program Manager Liudmila Mainzer\u2019s presentation focused on how NCSA works with industry partners to optimize workflows. She also showcased some of the computational genomics software programs that are available, but cautioned that the field is not yet \u201cfully baked.\u201d She said, \u201cMethodologies are developing at a rapid rate; while it\u2019s a challenge to keep up, we stay abreast of the resources that our partners need.\u201dSenior Database Architect Dora Cai described how her team develops time-saving solutions that translate to increased profits. One project reduced runtime from 3.5 hours to nine minutes using a parallelized, random forest algorithm. Another went from 175 days to four hours through use of a parallelized simulation program. Cai said, \u201cDL is more accurate than random forest\u201495 percent vs. 49 percent\u2014but the layers required with DL add time.\u201dTechnical Program Manager Ahmed Taha described the achievements of NCSA\u2019s modeling and simulation team. They support the new Chicago-based Digital Manufacturing and Design Innovation Institute (DMDII); an applied research institute that will develop a range of products for consumers and the U.S. Dept. of Defense. Taha said, \u201cDMDII, which partners with UIUC College of Engineering and NCSA, is supported by a $70 million DoD investment, and more than $250 million from industry, academia, government and community partners.Gropp and several presenters mentioned NCSA\u2019s cloud-enabled resource, Clowder; an open-source data-management tool that supports long-tail data that can be hosted in the cloud, on the desktop or via custom instance built with the assistance of NCSA experts. NCSA\u2019s Brown Dog tool is a science-driven, web-based, data-wrangling service that facilitates the extraction and representation of metadata from a variety of domains.Partnership Showcase PanelA special panel explored industry highlights from both technical and industry perspectives. Panel Moderator Andrew Jones (Vice President of HPC Numerical Algorithms Group) asked audience members if they had questions, concerns or additional success stories to share.One guest expressed concern that in-house technical staff might worry that their jobs would be in jeopardy if their company sought an alliance with NCSA, \u201cAnd that\u2019s who would normally steer such leadership decisions.\u201d Another expressed concern about the unintended consequences of AI, which led to a deeper discussion about the importance of interdisciplinary teams with representation from the social sciences\u2014something NCSA and their partners have established a track record for. Mark Brandyberry (Illinois Rocstar) said, \u201cNCSA was an easy choice for us. Compute capability and data science evolve quicker than our in-house techs can train,\u201d he said. \u201cIt\u2019s likely someone at NCSA knows how to solve whatever problem we\u2019re currently struggling with,\u201d he added. To Brandyberry\u2019s comment, someone said, \u201cnot everybody needs a supercomputer though; some just want Python to perform better on their laptop, and NCSA experts can help with that, too.\u201dNCSA Industry Program History; Video Highlights: Several NCSA Industry science and engineering highlights are described in their latest video, including some recent accomplishments by Caterpillar, Boeing and Eli Lilly. Additionally, their team assisted with the following:You\u2019ll find part one of the NCSA Industry Conference recap in HPCwire, including a summary of a keynote by Steven Demuth (Mayo Clinic Chief Technology Officer), and an introduction to the NCSA Viz Team.",
    "pic_urls": [
        "https://2pggys3b7fd63bfvol1w51zt-wpengine.netdna-ssl.com/wp-content/uploads/2018/10/NCSA-photosynthic-light-harvesting-1018-370x290.jpg",
        "https://2pggys3b7fd63bfvol1w51zt-wpengine.netdna-ssl.com/wp-content/uploads/2018/10/William-Gropp-Director-NCSA-1018.jpg",
        "https://2pggys3b7fd63bfvol1w51zt-wpengine.netdna-ssl.com/wp-content/uploads/2018/10/Liudmila-Mainzer-NCSA-Technical-Program-Manager.jpg"
    ]
}