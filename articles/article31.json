{
    "title": "Baidu Embraces Intel Optane for In-Memory Databases",
    "author": "George Leopold",
    "date": "2019-08-29 00:00:00",
    "text": "Chinese e-commerce giant Baidu is building a new platform based on Intel Corp.\u2019s Optane DC persistent memory as a means of upgrading search engine results delivered by its in-memory databases used to feed its streaming data services.The partners also published a case study\u00a0this week detailing the restructuring of its in-memory database using Optane memory technology introduced last year.The database effort is the latest in a decade-long collaboration between Baidu (NASDAQ: BIDU) and the U.S. chip maker (NASDAQ: INTC). The partners have been expanding their partnership\u00a0over the last several years to include AI projects spanning FPGA-backed workload acceleration, a deep learning framework based on Xeon Scalable processors and implementation of a vision processing unit.The new in-memory database effort would replace traditional DRAM by combining Optane persistent memory with Intel\u2019s second-generation Xeon Scalable processors. Along with reducing costs, the shift to Optane would accelerate the delivery of personalized search results via Baidu\u2019s \u201cFeed Stream\u201d recommendation engine.The expanded partnership was unveiled during a company event in Beijing this week.Baidu\u2019s in-memory database called Feed-Cube stores data and supports information retrieval via its cloud-based Feed Stream services. The partners said they built a hybrid system incorporating both Optane memory and DRAM within Feed Stream. The result was reduced search result response times \u201cunder the pressure of large concurrent access.\u201dMeanwhile, single-server DRAM demand dropped by more than half, providing what the partners asserted was a cost savings based on the Feed-Cube database\u2019s petabyte-scale storage capacity.Tao Wang, Baidu\u2019s chief architect for recommendation technology, said the Optane-DRAM combination running on the second-generation Xeon processor allowed it to \u201cscale memory capacity to stay on top of the continuously expanding demands placed on our Feed Stream services.\u201dBaidu said it would eventually shift the configuration of its Feed-Cube module from a hybrid mode using both DRAM and Optane to an Optane-only architecture. Baidu said DRAM has worked well as far as it goes, but huge data volumes are making scaling prohibitively expensive.\u201cThe use of expensive DRAM to build a large memory pool results in Baidu\u2019s [total cost of ownership] soaring while the limited capacity of DRAM also restricts further enhancement of the processing capability of Feed-Cube,\u201d the partners noted in a case study.According to the case study, Baidu tested NVMe SSDs and similar NVM-based storage devices to store data files and hash tables in Feed-Cube. Comparative testing of two clusters based on DRAM and NVMe SSDs revealed several shortcomings. For example, the SSDs displayed \u201cserious queueing delay\u201d running a large search application, thereby diminishing quality of service.NVMe also performed poorly when tested in a high-volume data storage scenario. The partners also identified a \u201cbig gap\u201d between SSD and DRAM I/O speed, according to the case study. Hence, expensive DRAM has to be added as system cache to ensure performance.(As workloads grow more demanding, memory makers\u00a0have addressed decreased bandwidth and increased latency by adding wider memory channels to increase bandwidth.)By contrast, Baidu reported the combination of Optane and 2nd-Gen Xeon allowed its Feed-Cube core module to boost memory density per device. The result was reduced cost in running a Redis in-memory database as well as a Spark distributed in-memory computing engine.As the movement of data between cloud storage and DRAM becomes a bottleneck, Baidu said it plans to incorporate Optane into its Spark-based platform to boost device memory density.The partners signed an agreement\u00a0on Aug. 1 to boost AI development along with autonomous driving, edge computing and related 5G wireless deployment. The goals include bringing high-end performance to Baidu\u2019s AI cloud, mobile search and feed streams and the Chinese company\u2019s deep learning platform, PaddlePaddle, among others.George Leopold has written about science and technology for more than 30 years, focusing on electronics and aerospace technology. He previously served as executive editor of Electronic Engineering Times. Leopold is the author of \"Calculated Risk: The Supersonic Life and Times of Gus Grissom\" (Purdue University Press, 2016).",
    "pic_urls": [
        "https://2pggys3b7fd63bfvol1w51zt-wpengine.netdna-ssl.com/wp-content/uploads/2019/07/Intel-Optane-Persistent-Memory-0719-370x290.jpg",
        "https://secure.gravatar.com/avatar/4b7d4d569774f21b5db4f21ac8c19c8d?s=80&r=g"
    ]
}