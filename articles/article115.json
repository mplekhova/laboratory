{
    "title": "IBM Bolsters Storage for AI, De-Dupe and Cloud DR",
    "author": "Alex Woodie",
    "date": "2018-05-11 00:00:00",
    "text": "IBM\u00a0made several announcements today designed to help customers get more out of their existing storage infrastructure, including IBM Storwize and FlashSystem arrays, the SAN Volume Controller (SVC) software-defined storage product, and even non-IBM arrays from\u00a0Dell EMC\u00a0and\u00a0HPE\u00a0that IBM storage software manages through its VersaStack program.Let\u2019s start with data de-duplication. For years IBM has offered de-dupe in its high-end FlashSystem A9000 array. Now it\u2019s tweaked that de-dupe code so it can run on IBM\u2019s Storwize, SVC, FlashSystem V9000, and the 440 external storage systems it supports via VersaStack.It\u2019s the first time IBM is providing de-dupe on those products, although it previously supported other data reduction techniques on them, including compression, thin provisioning, compaction, and SCSI unmap (which reclaims storage resources on arrays when virtual machines disconnect from them). Taken together, these five data reduction techniques can deliver up to a five-to-one reduction in the amount of raw data that organizations are storing on their IBM systems, IBM claims.Reduced storage requirements translate into big savings for customers. IBM says a five-to-one reduction in data can save a client that storing 700TB\u00a0 across 7.7TB flash drives in a Storwize V7000F $3.7 million in operating expenditures (opex) and $800,000 in capital expenditures (capex) over the course of three years. That big savings on big data can\u2019t be ignored.\u201cStorage analysts, depending on who you talk to, say the cost to manage 1TB of storage runs to $1,500 to $2,100 per year per terabyte,\u201d says Eric Herzog, chief marketing officer and VP of worldwide storage channels for IBM\u2019s Storage and Software Defined Infrastructure. \u201cSo if you don\u2019t have to buy as many terabytes, guess what? You reduce your capex as well.\u201dIBM is so confident that its big data reduction capabilities can save customers big money that it\u2019s making a big guarantee about it.\u201cWe don\u2019t care if you only do de-dupe or only do compression or do combination \u2014 the bottom line is you have data reductions guarantees,\u201d Herzog he tells\u00a0Datanami. \u201cYou can get up to five-to-one, which we can guarantee.\u201d (Customers will have to submit to a data analysis to get the five-to-one guarantee; IBM is guaranteeing at least a two-to-one reduction without the data analysis.)IBM also hopes to reduce the amount of money customers spend on storage through its new Storage Insights offering, which uses Watson-based artificial intelligence and machine learning capabilities to optimize storage requirements for customers\u2019 specific workloads, provide capacity planning capabilities, and otherwise optimize the storage environment.\u201cThe value is how to make sure you don\u2019t overbuy,\u201d Herzog says. \u201cYou\u2019ll be able to see the patterns and see what your historical use is so you can predictably look forward.\u201dFor the rest of this article, which originally appeared in sister publication Datanami, please use this link.Alex Woodie has written about IT as a technology journalist for more than a decade. He brings extensive experience from the IBM midrange marketplace, including topics such as servers, ERP applications, programming, databases, security, high availability, storage, business intelligence, cloud, and mobile enablement. He resides in the San Diego area.",
    "pic_urls": [
        "https://2pggys3b7fd63bfvol1w51zt-wpengine.netdna-ssl.com/wp-content/uploads/2017/05/Screen-Shot-2017-05-09-at-2.05.19-PM-370x290.png",
        "https://2s7gjr373w3x22jf92z99mgm5w-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/Storwize-savings-300x198.png",
        "https://secure.gravatar.com/avatar/b0307dd70ffe024a023722c06b737966?s=80&r=g"
    ]
}